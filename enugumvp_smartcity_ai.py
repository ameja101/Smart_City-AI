# -*- coding: utf-8 -*-
"""EnuguMVP_Smartcity_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYhD6dsuUJ7nNCzF_S_1QRy2PK5oYYft
"""

# Incident Detection + Bus ETA System

!pip install ultralytics osmnx folium streamlit_folium geopy flask-ngrok pyngrok

# Import libraries

import pandas as pd
import numpy as np
import os
from geopy.distance import geodesic
from math import radians, sin, cos, asin, sqrt
print("Environment ready.")

# Download Enugu Bus Stops from OpenStreetMap

import osmnx as ox
place = "Enugu, Nigeria"
bus_stops = ox.features.features_from_place(place, tags={"highway": "bus_stop"})
bus_stops[["name","geometry"]].to_csv("enugu_bus_stops.csv", index=False)
bus_stops.head()

# Incident Detection (YOLOv8) Setup

from ultralytics import YOLO
model = YOLO('yolov8n.pt') # tiny model for speed
test_video = "https://github.com/ultralytics/assets/releases/download/v0.0.0/bus.mp4"

# Incident Detection (YOLOv8) Setup

from ultralytics import YOLO
model = YOLO('yolov8n.pt') # tiny model for speed
test_video = "https://www.learningcontainer.com/wp-content/uploads/2020/05/sample-mp4-file.mp4"
!wget -O sample.mp4 $test_video

# Run YOLO Inference on Sample Video

results = model.predict(source="sample.mp4", save=True)
results

# Build Simple Incident Dataset CSV

import csv

# Create simple incident dataset CSV
with open("sample_incident_data_enugu.csv", "w", newline="") as f:
    writer = csv.writer(f)

    # Write header
    writer.writerow(["timestamp", "location", "incident_type", "vehicle_count"])

    # Write sample rows
    writer.writerow(["2025-01-10 08:30:00", "New Haven, Enugu", "stalled_vehicle", 12])
    writer.writerow(["2025-01-10 09:15:00", "Ogbete Market Road", "heavy_traffic", 25])
    writer.writerow(["2025-01-10 09:45:00", "Otigba Junction", "minor_collision", 8])
    writer.writerow(["2025-01-10 10:10:00", "Independence Layout", "congestion", 30])

print("CSV created successfully!")

# Build Bus ETA Predictor

 # --- Paste this entire cell into Colab and run it ---

import math
import pandas as pd

def haversine(lon1, lat1, lon2, lat2):
    """Return distance in kilometers between two points using haversine formula."""
    # convert decimal degrees to radians
    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])

    # haversine formula
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
    c = 2 * math.asin(math.sqrt(a))
    r = 6371  # Radius of Earth in kilometers
    return c * r

# Example Enugu bus stops (lat, lon)
bus_stops = pd.DataFrame({
    "stop_name": ["New Haven Junction", "Ogbete Market", "Mayor Bus Stop", "IMT Campus 2"],
    "lat": [6.4400, 6.4501, 6.4653, 6.4580],
    "lon": [7.4948, 7.4989, 7.5080, 7.5182]
})

# Compute distance between consecutive stops (km) and estimated travel time (min)
distances_km = []
for i in range(len(bus_stops) - 1):
    lat1, lon1 = bus_stops.loc[i, ["lat", "lon"]]
    lat2, lon2 = bus_stops.loc[i + 1, ["lat", "lon"]]
    dist = haversine(lon1, lat1, lon2, lat2)
    distances_km.append(dist)

# last stop has no 'next' stop
distances_km.append(0.0)
bus_stops["distance_to_next_km"] = distances_km

# assume average speed (adjustable)
average_speed_kmh = 25.0
bus_stops["travel_time_min"] = (bus_stops["distance_to_next_km"] / average_speed_kmh) * 60.0

bus_stops

# --- PROPHET ETA PREDICTOR FOR ENUGU BUS ROUTES ---

!pip uninstall prophet -y
!pip uninstall pystan -y
!pip install pystan --quiet
!pip install prophet --quiet

import pandas as pd
import numpy as np
from prophet import Prophet
import matplotlib.pyplot as plt

# -------------------------------
# 1. Create Synthetic Bus Travel-Time Dataset
# -------------------------------

# Simulate 60 days of historical travel time between:
# New Haven → Ogbete Market → Mayor Bus Stop → IMT Campus 2
# Focus: segment 1 (New Haven → Ogbete), we can extend later

np.random.seed(42)

days = pd.date_range(start="2024-11-01", periods=60, freq="D")
base_travel_time = 6  # base travel mins (light traffic)

# Add realistic Enugu traffic variations:
# Morning peak: +4 min
# Evening peak: +3 min
# Random jitter: 2 min

travel_times = []
for d in days:
    t = base_travel_time

    # morning rush (7–9 AM)
    if 7 <= d.hour <= 9:
        t += 4

    # evening slows down (4–6 PM)
    if 16 <= d.hour <= 18:
        t += 3

    # daily noise
    t += np.random.randint(-2, 3)

    travel_times.append(t)

df = pd.DataFrame({
    "ds": days,
    "y": travel_times
})

display(df.head())

# -------------------------------
# 2. Train Prophet Model
# -------------------------------

model = Prophet(
    interval_width=0.85,
    daily_seasonality=True,
    weekly_seasonality=True
)
model.fit(df)

# -------------------------------
# 3. Forecast next 24 hours travel time
# -------------------------------

future = model.make_future_dataframe(periods=24, freq="H")
forecast = model.predict(future)

# -------------------------------
# 4. Visualize forecast
# -------------------------------

fig1 = model.plot(forecast)
plt.title("Bus ETA Prediction (New Haven → Ogbete Market)")
plt.xlabel("Date")
plt.ylabel("Travel Time (minutes)")
plt.show()

fig2 = model.plot_components(forecast)
plt.show()

# -------------------------------
# 5. Extract next ETA prediction
# -------------------------------

next_prediction = forecast.iloc[-1][["ds", "yhat", "yhat_lower", "yhat_upper"]]
next_prediction

print("Notebook execution complete.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile ingest.py
# import sqlite3
# import datetime
# from flask import Flask, request, jsonify
# import os
# 
# app = Flask(__name__)
# 
# # Choose DB type
# USE_SQLITE = True   # set False if using Postgres
# 
# if USE_SQLITE:
#     DB = "smartcity.db"
#     conn = sqlite3.connect(DB, check_same_thread=False)
# else:
#     import psycopg2
#     conn = psycopg2.connect(
#         dbname=os.environ.get("POSTGRES_DB", "smartcity"),
#         user=os.environ.get("POSTGRES_USER", "postgres"),
#         password=os.environ.get("POSTGRES_PASSWORD", "postgres"),
#         host=os.environ.get("POSTGRES_HOST", "localhost"),
#         port=5432
#     )
# 
# cur = conn.cursor()
# 
# # Create table if not exists
# cur.execute("""
# CREATE TABLE IF NOT EXISTS vehicle_pings (
#     id INTEGER PRIMARY KEY AUTOINCREMENT,
#     vehicle_id TEXT,
#     lat REAL,
#     lon REAL,
#     ts TEXT
# )
# """)
# conn.commit()
# 
# 
# @app.route("/ping", methods=["POST"])
# def ingest_ping():
#     data = request.json
# 
#     vehicle_id = data.get("vehicle_id")
#     lat = data.get("lat")
#     lon = data.get("lon")
#     ts = data.get("ts", datetime.datetime.utcnow().isoformat())
# 
#     if not vehicle_id or lat is None or lon is None:
#         return jsonify({"error": "Missing fields"}), 400
# 
#     cur.execute(
#         "INSERT INTO vehicle_pings (vehicle_id, lat, lon, ts) VALUES (?, ?, ?, ?)",
#         (vehicle_id, lat, lon, ts)
#     )
#     conn.commit()
# 
#     return jsonify({"status": "ok"}), 200
# 
# 
# @app.route("/latest", methods=["GET"])
# def get_latest():
#     cur.execute("SELECT vehicle_id, lat, lon, ts FROM vehicle_pings ORDER BY id DESC LIMIT 50")
#     rows = cur.fetchall()
# 
#     return jsonify([
#         {"vehicle_id": r[0], "lat": r[1], "lon": r[2], "ts": r[3]}
#         for r in rows
#     ])
# 
# 
# if __name__ == "__main__":
#     app.run(host="0.0.0.0", port=5001)
#

!pip install waitress pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile wsgi.py
# 
# from ingest import app
# from waitress import serve
# 
# if __name__ == "__main__":
#     serve(app, host="0.0.0.0", port=5001)
#

from pyngrok import ngrok

# Get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken
ngrok.set_auth_token("35m5GJUasSYxEuqbjURsLxCMBMg_27nrXTLe6FvkRVP1c3Gof")

public_url = ngrok.connect(addr=5001, hostname="virgilio-epiphenomenal-halina.ngrok-free.dev")
public_url

!python wsgi.py

# Commented out IPython magic to ensure Python compatibility.
# %%writefile gps_simulator.py
# import time
# import requests
# import random
# 
# url = "https://virgilio-epiphenomenal-halina.ngrok-free.dev" # ingest API endpoint
# 
# # Simulated bus route: New Haven → Ogbete → Mayor → IMT Campus 2
# route = [
#     (6.4400, 7.4948),
#     (6.4501, 7.4989),
#     (6.4653, 7.5080),
#     (6.4580, 7.5182),
# ]
# 
# while True:
#     for lat, lon in route:
#         # Add tiny random noise to mimic GPS drift
#         lat += random.uniform(-0.0005, 0.0005)
#         lon += random.uniform(-0.0005, 0.0005)
# 
#         r = requests.post(url, json={
#             "vehicle_id": "bus1",
#             "lat": lat,
#             "lon": lon
#         })
# 
#         print("Sent GPS ping:", lat, lon, "| Status:", r.status_code)
#         time.sleep(3)  # wait 3 seconds before next ping
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile streamlit_app.py
# from math import radians, sin, cos, atan2, sqrt
# 
# def haversine(lat1, lon1, lat2, lon2):
#     # Convert to radians
#     lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
# 
#     # Haversine formula
#     dlon = lon2 - lon1
#     dlat = lat2 - lat1
#     a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
#     c = 2 * atan2(sqrt(a), sqrt(1 - a))
# 
#     r = 6371  # Earth radius in km
#     return r * c
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile run_onnx.py
# import cv2
# import time
# 
# cap = cv2.VideoCapture(0)
# 
# if not cap.isOpened():
#     print("Error: Cannot open camera")
#     exit()
# 
# while True:
#     ret, frame = cap.read()   # <-- MUST be indented under while
# 
#     if not ret:
#         print("Failed to grab frame")
#         break
# 
#     cv2.imshow("Smart City – Camera Feed", frame)
# 
#     # Press Q to quit
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         break
# 
# # Cleanup
# cap.release()
# cv2.destroyAllWindows()
# 
#